openapi: 3.0.1
info:
  title: Azure AI Foundry Service API
  description: Azure AI Foundry APIs for completions and chat
  version: '2024-06-01'
servers:
  - url: https://REPLACE-BY-POLICY.azure-api.net/ai-foundry
paths:
  '/deployments/{deployment-id}/completions':
    post:
      summary: 'Creates a completion for the provided prompt, parameters and chosen model via AI Foundry.'
      description: 'Creates a completion for the provided prompt, parameters and chosen model via AI Foundry.'
      operationId: AiFoundryCompletions_Create
      parameters:
        - name: deployment-id
          in: path
          required: true
          schema:
            type: string
            description: Deployment id of the model which was deployed.
            example: gpt-4o-mini
        - name: api-version
          in: query
          required: true
          schema:
            type: string
            description: api version
            example: '2024-06-01'
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                prompt:
                  oneOf:
                    - type: string
                      default: ''
                      nullable: true
                      example: This is a test.
                    - type: array
                      items:
                        type: string
                        default: ''
                        example: This is a test.
                      description: Array size minimum of 1 and maximum of 2048
                  description: "The prompt(s) to generate completions for, encoded as a string or array of strings.\nNote that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document. Maximum allowed size of string list is 2048."
                max_tokens:
                  type: integer
                  description: 'The token count of your prompt plus max_tokens cannot exceed the model''s context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096). Has minimum of 0.'
                  default: 16
                  nullable: true
                  example: 16
                temperature:
                  type: number
                  description: "What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\nWe generally recommend altering this or top_p but not both."
                  default: 1
                  nullable: true
                  example: 1
                top_p:
                  type: number
                  description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend altering this or temperature but not both."
                  default: 1
                  nullable: true
                  example: 1
                logit_bias:
                  type: object
                  description: 'Defaults to null. Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. As an example, you can pass {"50256" &#58; -100} to prevent the <|endoftext|> token from being generated.'
                user:
                  type: string
                  description: 'A unique identifier representing your end-user, which can help monitoring and detecting abuse'
                n:
                  type: integer
                  description: "How many completions to generate for each prompt. Minimum of 1 and maximum of 128 allowed.\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."
                  default: 1
                  nullable: true
                  example: 1
                stream:
                  type: boolean
                  description: 'Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message.'
                  default: false
                  nullable: true
                logprobs:
                  type: integer
                  description: "Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response.\nMinimum of 0 and maximum of 5 allowed."
                  default: 
                  nullable: true
                suffix:
                  type: string
                  description: The suffix that comes after a completion of inserted text.
                  nullable: true
                echo:
                  type: boolean
                  description: Echo back the prompt in addition to the completion
                  default: false
                  nullable: true
                stop:
                  oneOf:
                    - type: string
                      default: <|endoftext|>
                      nullable: true
                      example: ''
                    - type: array
                      items:
                        type: string
                        example: ''
                      description: Array minimum size of 1 and maximum of 4
                  description: Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
                completion_config:
                  type: string
                  nullable: true
                presence_penalty:
                  type: number
                  description: 'Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model''s likelihood to talk about new topics.'
                  default: 0
                frequency_penalty:
                  type: number
                  description: 'Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model''s likelihood to repeat the same line verbatim.'
                  default: 0
                best_of:
                  type: integer
                  description: "Generates best_of completions server-side and returns the \"best\" (the one with the highest log probability per token). Results cannot be streamed.\nWhen used with n, best_of controls the number of candidate completions and n specifies how many to return - best_of must be greater than n.\nNote: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop. Has maximum value of 128."
            example:
              prompt: "Negate the following sentence.The price for bubblegum increased on thursday.\n Negated Sentence:"
              max_tokens: 50
      responses:
        '200':
          description: OK
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                required:
                  - id
                  - object
                  - created
                  - model
                  - choices
                type: object
                properties:
                  id:
                    type: string
                  object:
                    type: string
                  created:
                    type: integer
                  model:
                    type: string
                  prompt_filter_results:
                    $ref: '#/components/schemas/promptFilterResults'
                  choices:
                    type: array
                    items:
                      type: object
                      properties:
                        text:
                          type: string
                        index:
                          type: integer
                        logprobs:
                          type: object
                          properties:
                            tokens:
                              type: array
                              items:
                                type: string
                            token_logprobs:
                              type: array
                              items:
                                type: number
                            top_logprobs:
                              type: array
                              items:
                                type: object
                                additionalProperties:
                                  type: number
                            text_offset:
                              type: array
                              items:
                                type: integer
                          nullable: true
                        finish_reason:
                          type: string
                        content_filter_results:
                          $ref: '#/components/schemas/contentFilterChoiceResults'
                  usage:
                    required:
                      - prompt_tokens
                      - total_tokens
                      - completion_tokens
                    type: object
                    properties:
                      completion_tokens:
                        type: number
                        format: int32
                      prompt_tokens:
                        type: number
                        format: int32
                      total_tokens:
                        type: number
                        format: int32
              example:
                model: gpt-4o-mini
                object: text_completion
                id: cmpl-4509KAos68kxOqpE2uYGw81j6m7uo
                created: 1637097562
                choices:
                  - index: 0
                    text: The price for bubblegum decreased on thursday.
                    logprobs: 
                    finish_reason: stop
            text/event-stream:
              schema:
                type: string
                description: 'Server-sent events for streaming responses when stream=true'
        '400':
          description: Service unavailable
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
        '500':
          description: Service unavailable
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
  '/deployments/{deployment-id}/chat/completions':
    post:
      summary: Creates a completion for the chat message via AI Foundry
      description: Creates a completion for the chat message via AI Foundry
      operationId: AiFoundryChatCompletions_Create
      parameters:
        - name: deployment-id
          in: path
          required: true
          schema:
            enum:
              - chat
              - gpt-4o-mini
            type: string
            description: Deployment id of the model which was deployed.
            default: chat
        - name: api-version
          in: query
          required: true
          schema:
            enum:
              - '2024-06-01'
            type: string
            description: api version
            default: '2024-06-01'
            example: '2024-06-01'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/createChatCompletionRequest'
            example:
              model: chat
              messages:
                - role: system
                  content: You are a helpful assistant that responds in Markdown. Help me with my math homework!
                - role: user
                  content: How to calculate the distance between earth and moon?
      responses:
        '200':
          description: OK
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/createChatCompletionResponse'
            text/event-stream:
              schema:
                type: string
                description: 'Server-sent events for streaming responses when stream=true'
        '400':
          description: Service unavailable
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
        '500':
          description: Service unavailable
          headers:
            apim-request-id:
              description: Request ID for troubleshooting purposes
              schema:
                type: string
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
components:
  schemas:
    errorResponse:
      type: object
      properties:
        error:
          $ref: '#/components/schemas/error'
    errorBase:
      type: object
      properties:
        code:
          type: string
        message:
          type: string
    error:
      type: object
      allOf:
        - $ref: '#/components/schemas/errorBase'
      properties:
        param:
          type: string
        type:
          type: string
        inner_error:
          $ref: '#/components/schemas/innerError'
    innerError:
      type: object
      properties:
        code:
          $ref: '#/components/schemas/innerErrorCode'
        content_filter_results:
          $ref: '#/components/schemas/contentFilterPromptResults'
      description: Inner error with additional details.
    innerErrorCode:
      enum:
        - ResponsibleAIPolicyViolation
      type: string
      description: Error codes for the inner error object.
      x-ms-enum:
        name: InnerErrorCode
        modelAsString: true
        values:
          - value: ResponsibleAIPolicyViolation
            description: The prompt violated one of more content filter rules.
    contentFilterResultBase:
      required:
        - filtered
      type: object
      properties:
        filtered:
          type: boolean
    contentFilterSeverityResult:
      required:
        - severity
        - filtered
      type: object
      allOf:
        - $ref: '#/components/schemas/contentFilterResultBase'
        - properties:
            severity:
              enum:
                - safe
                - low
                - medium
                - high
              type: string
              x-ms-enum:
                name: ContentFilterSeverity
                modelAsString: true
                values:
                  - value: safe
                    description: General content or related content in generic or non-harmful contexts.
                  - value: low
                    description: Harmful content at a low intensity and risk level.
                  - value: medium
                    description: Harmful content at a medium intensity and risk level.
                  - value: high
                    description: Harmful content at a high intensity and risk level.
    contentFilterDetectedResult:
      required:
        - detected
        - filtered
      type: object
      allOf:
        - $ref: '#/components/schemas/contentFilterResultBase'
        - properties:
            detected:
              type: boolean
    contentFilterResultsBase:
      type: object
      properties:
        sexual:
          $ref: '#/components/schemas/contentFilterSeverityResult'
        violence:
          $ref: '#/components/schemas/contentFilterSeverityResult'
        hate:
          $ref: '#/components/schemas/contentFilterSeverityResult'
        self_harm:
          $ref: '#/components/schemas/contentFilterSeverityResult'
        profanity:
          $ref: '#/components/schemas/contentFilterDetectedResult'
        error:
          $ref: '#/components/schemas/errorBase'
      description: Information about the content filtering results.
    contentFilterPromptResults:
      type: object
      allOf:
        - $ref: '#/components/schemas/contentFilterResultsBase'
        - properties:
            jailbreak:
              $ref: '#/components/schemas/contentFilterDetectedResult'
      description: 'Information about the content filtering category (hate, sexual, violence, self_harm), if it has been detected, as well as the severity level (very_low, low, medium, high-scale that determines the intensity and risk level of harmful content) and if it has been filtered or not. Information about jailbreak content and profanity, if it has been detected, and if it has been filtered or not. And information about customer block list, if it has been filtered and its id.'
    contentFilterChoiceResults:
      type: object
      allOf:
        - $ref: '#/components/schemas/contentFilterResultsBase'
        - properties:
            protected_material_text:
              $ref: '#/components/schemas/contentFilterDetectedResult'
        - properties:
            protected_material_code:
              $ref: '#/components/schemas/contentFilterDetectedResult'
      description: 'Information about the content filtering category (hate, sexual, violence, self_harm), if it has been detected, as well as the severity level (very_low, low, medium, high-scale that determines the intensity and risk level of harmful content) and if it has been filtered or not. Information about third party text and profanity, if it has been detected, and if it has been filtered or not. And information about customer block list, if it has been filtered and its id.'
    promptFilterResult:
      type: object
      properties:
        prompt_index:
          type: integer
        content_filter_results:
          $ref: '#/components/schemas/contentFilterPromptResults'
      description: Content filtering results for a single prompt in the request.
    promptFilterResults:
      type: array
      items:
        $ref: '#/components/schemas/promptFilterResult'
      description: 'Content filtering results for zero or more prompts in the request. In a streaming request, results for different prompts may arrive at different times or in different orders.'
    chatCompletionsRequestCommon:
      type: object
      properties:
        temperature:
          maximum: 2.0
          minimum: 0.0
          type: number
          description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both."
          default: 1
          nullable: true
          example: 1
        top_p:
          maximum: 1.0
          minimum: 0.0
          type: number
          description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\nWe generally recommend altering this or `temperature` but not both."
          default: 1
          nullable: true
          example: 1
        stream:
          type: boolean
          description: 'If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a `data: [DONE]` message.'
          default: false
          nullable: true
        stop:
          oneOf:
            - type: string
              nullable: true
            - maxItems: 4
              minItems: 1
              type: array
              items:
                type: string
              description: Array minimum size of 1 and maximum of 4
          description: Up to 4 sequences where the API will stop generating further tokens.
          default: 
        max_tokens:
          type: integer
          description: 'The maximum number of tokens allowed for the generated answer. By default, the number of tokens the model can return will be (4096 - prompt tokens).'
          default: 4096
        presence_penalty:
          maximum: 2.0
          minimum: -2.0
          type: number
          description: 'Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model''s likelihood to talk about new topics.'
          default: 0
        frequency_penalty:
          maximum: 2.0
          minimum: -2.0
          type: number
          description: 'Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model''s likelihood to repeat the same line verbatim.'
          default: 0
        logit_bias:
          type: object
          description: 'Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.'
          nullable: true
        user:
          type: string
          description: 'A unique identifier representing your end-user, which can help Azure AI Foundry to monitor and detect abuse.'
          example: user-1234
    createChatCompletionRequest:
      required:
        - messages
      type: object
      allOf:
        - $ref: '#/components/schemas/chatCompletionsRequestCommon'
        - properties:
            messages:
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/chatCompletionRequestMessage'
              description: 'A list of messages comprising the conversation so far.'
            n:
              maximum: 128.0
              minimum: 1.0
              type: integer
              description: How many chat completion choices to generate for each input message.
              default: 1
              nullable: true
              example: 1
            seed:
              maximum: 9223372036854775800
              minimum: -9223372036854775800
              type: integer
              description: 'If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.'
              default: 0
              nullable: true
              example: 1
            logprobs:
              type: boolean
              description: 'Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`.'
              default: false
              nullable: true
            top_logprobs:
              maximum: 5.0
              minimum: 0.0
              type: integer
              description: 'An integer between 0 and 5 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used.'
              nullable: true
            response_format:
              type: object
              properties:
                type:
                  $ref: '#/components/schemas/chatCompletionResponseFormat'
              description: An object specifying the format that the model must output. Used to enable JSON mode.
            tools:
              minItems: 1
              type: array
              items:
                $ref: '#/components/schemas/chatCompletionTool'
              description: 'A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.'
            tool_choice:
              $ref: '#/components/schemas/chatCompletionToolChoiceOption'
    chatCompletionResponseFormat:
      enum:
        - text
        - json_object
      type: string
      description: Setting to `json_object` enables JSON mode. This guarantees that the message the model generates is valid JSON.
      default: text
      nullable: true
      example: json_object
      x-ms-enum:
        name: ChatCompletionResponseFormat
        modelAsString: true
        values:
          - value: text
            description: Response format is a plain text string.
          - value: json_object
            description: Response format is a JSON object.
    chatCompletionRequestMessage:
      required:
        - role
      type: object
      properties:
        role:
          $ref: '#/components/schemas/chatCompletionRequestMessageRole'
      discriminator:
        propertyName: role
        mapping:
          system: '#/components/schemas/chatCompletionRequestMessageSystem'
          user: '#/components/schemas/chatCompletionRequestMessageUser'
          assistant: '#/components/schemas/chatCompletionRequestMessageAssistant'
          tool: '#/components/schemas/chatCompletionRequestMessageTool'
    chatCompletionRequestMessageRole:
      enum:
        - system
        - user
        - assistant
        - tool
      type: string
      description: The role of the messages author.
      x-ms-enum:
        name: ChatCompletionRequestMessageRole
        modelAsString: true
        values:
          - value: system
            description: The message author role is system.
          - value: user
            description: The message author role is user.
          - value: assistant
            description: The message author role is assistant.
          - value: tool
            description: The message author role is tool.
    chatCompletionRequestMessageSystem:
      required:
        - content
      allOf:
        - $ref: '#/components/schemas/chatCompletionRequestMessage'
        - type: object
          properties:
            content:
              type: string
              description: The contents of the message.
              nullable: true
    chatCompletionRequestMessageUser:
      required:
        - content
      allOf:
        - $ref: '#/components/schemas/chatCompletionRequestMessage'
        - type: object
          properties:
            content:
              oneOf:
                - type: string
                  description: The contents of the message.
                - minimum: 1.0
                  type: array
                  items:
                    $ref: '#/components/schemas/chatCompletionRequestMessageContentPart'
                  description: 'An array of content parts with a defined type, each can be of type `text` or `image_url` when passing in images.'
              nullable: true
    chatCompletionRequestMessageContentPart:
      required:
        - type
      type: object
      properties:
        type:
          $ref: '#/components/schemas/chatCompletionRequestMessageContentPartType'
      discriminator:
        propertyName: type
        mapping:
          text: '#/components/schemas/chatCompletionRequestMessageContentPartText'
          image_url: '#/components/schemas/chatCompletionRequestMessageContentPartImage'
    chatCompletionRequestMessageContentPartType:
      enum:
        - text
        - image_url
      type: string
      description: The type of the content part.
      x-ms-enum:
        name: ChatCompletionRequestMessageContentPartType
        modelAsString: true
        values:
          - value: text
            description: The content part type is text.
          - value: image_url
            description: The content part type is image_url.
    chatCompletionRequestMessageContentPartText:
      required:
        - text
      allOf:
        - $ref: '#/components/schemas/chatCompletionRequestMessageContentPart'
        - type: object
          properties:
            text:
              type: string
              description: The text content.
    chatCompletionRequestMessageContentPartImage:
      required:
        - url
      allOf:
        - $ref: '#/components/schemas/chatCompletionRequestMessageContentPart'
        - type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
            detail:
              $ref: '#/components/schemas/imageDetailLevel'
    imageDetailLevel:
      enum:
        - auto
        - low
        - high
      type: string
      description: Specifies the detail level of the image.
      default: auto
      x-ms-enum:
        name: ImageDetailLevel
        modelAsString: true
        values:
          - value: auto
            description: The image detail level is auto.
          - value: low
            description: The image detail level is low.
          - value: high
            description: The image detail level is high.
    chatCompletionRequestMessageAssistant:
      required:
        - content
      allOf:
        - $ref: '#/components/schemas/chatCompletionRequestMessage'
        - type: object
          properties:
            content:
              type: string
              description: The contents of the message.
              nullable: true
            tool_calls:
              type: array
              items:
                $ref: '#/components/schemas/chatCompletionMessageToolCall'
              description: 'The tool calls generated by the model, such as function calls.'
    chatCompletionMessageToolCall:
      required:
        - id
        - type
        - function
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call.
        type:
          $ref: '#/components/schemas/toolCallType'
        function:
          required:
            - name
            - arguments
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: 'The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function.'
          description: The function that the model called.
    toolCallType:
      enum:
        - function
      type: string
      description: 'The type of the tool call, in this case `function`.'
      x-ms-enum:
        name: ToolCallType
        modelAsString: true
        values:
          - value: function
            description: The tool call type is function.
    chatCompletionRequestMessageTool:
      required:
        - tool_call_id
        - content
      allOf:
        - $ref: '#/components/schemas/chatCompletionRequestMessage'
        - type: object
          properties:
            tool_call_id:
              type: string
              description: Tool call that this message is responding to.
            content:
              type: string
              description: The contents of the message.
              nullable: true
          nullable: true
    createChatCompletionResponse:
      required:
        - id
        - object
        - created
        - model
        - choices
      type: object
      allOf:
        - $ref: '#/components/schemas/chatCompletionsResponseCommon'
        - properties:
            prompt_filter_results:
              $ref: '#/components/schemas/promptFilterResults'
            choices:
              type: array
              items:
                type: object
                allOf:
                  - $ref: '#/components/schemas/chatCompletionChoiceCommon'
                  - properties:
                      message:
                        $ref: '#/components/schemas/chatCompletionResponseMessage'
                      content_filter_results:
                        $ref: '#/components/schemas/contentFilterChoiceResults'
                      logprobs:
                        $ref: '#/components/schemas/chatCompletionChoiceLogProbs'
    chatCompletionChoiceLogProbs:
      required:
        - content
      type: object
      properties:
        content:
          type: array
          items:
            $ref: '#/components/schemas/chatCompletionTokenLogprob'
          description: A list of message content tokens with log probability information.
          nullable: true
      description: Log probability information for the choice.
      nullable: true
    chatCompletionTokenLogprob:
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
      type: object
      properties:
        token:
          type: string
          description: The token.
        logprob:
          type: number
          description: The log probability of this token.
        bytes:
          type: array
          items:
            type: integer
          description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
          nullable: true
        top_logprobs:
          type: array
          items:
            required:
              - token
              - logprob
              - bytes
            type: object
            properties:
              token:
                type: string
                description: The token.
              logprob:
                type: number
                description: The log probability of this token.
              bytes:
                type: array
                items:
                  type: integer
                description: A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token.
                nullable: true
          description: 'List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned.'
    chatCompletionResponseMessage:
      type: object
      properties:
        role:
          $ref: '#/components/schemas/chatCompletionResponseMessageRole'
        content:
          type: string
          description: The contents of the message.
          nullable: true
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/chatCompletionMessageToolCall'
          description: 'The tool calls generated by the model, such as function calls.'
      description: A chat completion message generated by the model.
    chatCompletionResponseMessageRole:
      enum:
        - assistant
      type: string
      description: The role of the author of the response message.
    chatCompletionToolChoiceOption:
      oneOf:
        - enum:
            - none
            - auto
            - required
          type: string
          description: '`none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.'
        - $ref: '#/components/schemas/chatCompletionNamedToolChoice'
      description: 'Controls which (if any) function is called by the model. `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function. Specifying a particular function via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that function.'
    chatCompletionNamedToolChoice:
      type: object
      properties:
        type:
          enum:
            - function
          type: string
          description: 'The type of the tool. Currently, only `function` is supported.'
        function:
          required:
            - name
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
      description: Specifies a tool the model should use. Use to force the model to call a specific function.
    chatCompletionsResponseCommon:
      required:
        - id
        - object
        - created
        - model
      type: object
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        object:
          $ref: '#/components/schemas/chatCompletionResponseObject'
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
          format: unixtime
        model:
          type: string
          description: The model used for the chat completion.
        usage:
          $ref: '#/components/schemas/completionUsage'
        system_fingerprint:
          type: string
          description: Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
    chatCompletionResponseObject:
      enum:
        - chat.completion
      type: string
      description: The object type.
      x-ms-enum:
        name: ChatCompletionResponseObject
        modelAsString: true
        values:
          - value: chat.completion
            description: The object type is chat completion.
    completionUsage:
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      type: object
      properties:
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
      description: Usage statistics for the completion request.
    chatCompletionTool:
      required:
        - type
        - function
      type: object
      properties:
        type:
          $ref: '#/components/schemas/chatCompletionToolType'
        function:
          required:
            - name
            - parameters
          type: object
          properties:
            description:
              type: string
              description: 'A description of what the function does, used by the model to choose when and how to call the function.'
            name:
              type: string
              description: 'The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'
            parameters:
              $ref: '#/components/schemas/chatCompletionFunctionParameters'
    chatCompletionToolType:
      enum:
        - function
      type: string
      description: 'The type of the tool. Currently, only `function` is supported.'
      x-ms-enum:
        name: ChatCompletionToolType
        modelAsString: true
        values:
          - value: function
            description: The tool type is function.
    chatCompletionFunctionParameters:
      type: object
      description: 'The parameters the functions accepts, described as a JSON Schema object.'
    chatCompletionChoiceCommon:
      type: object
      properties:
        index:
          type: integer
        finish_reason:
          type: string
  securitySchemes:
    apiKeyHeader:
      type: apiKey
      name: api-key
      in: header
    apiKeyQuery:
      type: apiKey
      name: subscription-key
      in: query
security:
  - apiKeyHeader: [ ]
  - apiKeyQuery: [ ]
